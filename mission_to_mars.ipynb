{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission to Mars\n",
    "\n",
    "![mission_to_mars](Images/mission_to_mars.jpg)\n",
    "\n",
    "\n",
    "In this assignment, you will build a web application that scrapes various websites for data related to the Mission to Mars and displays the information in a single HTML page. The following outlines what you need to do.\n",
    "\n",
    "## Step 1 - Scraping\n",
    "\n",
    "Complete your initial scraping using Jupyter Notebook, BeautifulSoup, Pandas, and Requests/Splinter.\n",
    "\n",
    "* Create a Jupyter Notebook file called `mission_to_mars.ipynb` and use this to complete all of your scraping and analysis tasks. The following outlines what you need to scrape.\n",
    "### NASA Mars News\n",
    "\n",
    "\n",
    " Scrape the [NASA Mars News Site](https://mars.nasa.gov/news/) and collect the latest News Title and Paragragh Text. Assign the text to variables that you can reference later.\n",
    "\n",
    "```python\n",
    "# Example:\n",
    "# news_title = \"NASA's Next Mars Mission to Investigate Interior of Red Planet\"\n",
    "\n",
    "# news_p = \"Preparation of NASA's next spacecraft to Mars, InSight, has ramped up this summer, on course for launch next May from Vandenberg Air Force Base in central California -- the first interplanetary launch in history from America's West Coast.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from difflib import SequenceMatcher\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_url = 'https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(article_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_results = soup.find_all('div', class_=\"content_title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_titles = []\n",
    "\n",
    "for result in title_results:\n",
    "    title_text = result.text.strip()\n",
    "    news_titles.append(title_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Opportunity Hunkers Down During Dust Storm',\n",
       " 'NASA Finds Ancient Organic Material, Mysterious Methane on Mars',\n",
       " 'NASA Invests in Visionary Technology',\n",
       " 'NASA is Ready to Study the Heart of Mars',\n",
       " 'NASA Briefing on First Mission to Study Mars Interior',\n",
       " \"New 'AR' Mobile App Features 3-D NASA Spacecraft\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Opportunity Hunkers Down During Dust Storm'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_title = news_titles[0]\n",
    "news_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_news_title(article_url):\n",
    "    \"\"\"Returns the latest News Article from the article url provided\"\"\"\n",
    "    \n",
    "    response = requests.get(article_url)\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    title_results = soup.find_all('div', class_=\"content_title\")\n",
    "    \n",
    "    news_titles = []\n",
    "\n",
    "    for result in title_results:\n",
    "        title_text = result.text.strip()\n",
    "        news_titles.append(title_text)\n",
    "    \n",
    "    news_title = news_titles[0]\n",
    "    return news_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Opportunity Hunkers Down During Dust Storm'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_latest_news_title(article_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_results = soup.find_all('div', class_=\"rollover_description_inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_descriptions = []\n",
    "\n",
    "for result in description_results:\n",
    "    description_text = result.text.strip()\n",
    "    news_descriptions.append(description_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NASA engineers attempted to contact the Opportunity rover today but did not hear back from the nearly 15-year old rover.',\n",
       " 'NASA’s Curiosity rover has found evidence on Mars with implications for NASA’s search for life.',\n",
       " 'NASA is investing in technology concepts, including several from JPL, that may one day be used for future space exploration missions.',\n",
       " 'NASA is about to go on a journey to study the center of Mars.',\n",
       " 'NASA’s next mission to Mars will be the topic of a media briefing Thursday, March 29, at JPL. The briefing will air live on NASA Television and the agency’s website.',\n",
       " \"NASA spacecraft travel to far-off destinations in space, but a new mobile app produced by NASA's Jet Propulsion Laboratory, Pasadena, California, brings spacecraft to users.\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NASA engineers attempted to contact the Opportunity rover today but did not hear back from the nearly 15-year old rover.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_description = news_descriptions[0]\n",
    "news_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_news_description (article_url):\n",
    "    \"\"\"Returns a description of the latest news article from the url provided\"\"\"\n",
    "    \n",
    "    response = requests.get(article_url)\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    description_results = soup.find_all('div', class_=\"rollover_description_inner\")\n",
    "    \n",
    "    news_descriptions = []\n",
    "\n",
    "    for result in description_results:\n",
    "        description_text = result.text.strip()\n",
    "        news_descriptions.append(description_text)\n",
    "        \n",
    "    news_description = news_descriptions[0]\n",
    "    \n",
    "    return news_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NASA engineers attempted to contact the Opportunity rover today but did not hear back from the nearly 15-year old rover.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_latest_news_description(article_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/chromedriver\r\n"
     ]
    }
   ],
   "source": [
    "!which chromedriver\n",
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_feature_image():\n",
    "    \"\"\"Returns feature image url from NASA's website\"\"\"\n",
    "    \n",
    "    image_url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    \n",
    "    !which chromedriver\n",
    "    executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    browser.visit(image_url)\n",
    "    \n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    feature_images = soup.find_all('article', class_='carousel_item')\n",
    "\n",
    "    def similar(a, b):\n",
    "        return SequenceMatcher(None, a, b).ratio()\n",
    "    \n",
    "    image_tags = []\n",
    "\n",
    "    for item in feature_images:\n",
    "        target_item = str(item.a)\n",
    "        split_target = target_item.split(\" \")\n",
    "        image_tags.append(split_target)\n",
    "\n",
    "    text_list = []\n",
    "    score_list = []\n",
    "\n",
    "    for y in image_tags[0]:\n",
    "\n",
    "        similarity = similar(y, 'data-fancybox-href=\"/spaceimages/images/')\n",
    "\n",
    "        text_list.append(y)\n",
    "        score_list.append(similarity)\n",
    "\n",
    "    target_url = str(text_list[score_list.index(max(score_list))])\n",
    "    target_url_list = target_url.split('\"')\n",
    "\n",
    "    beg_url = 'https://www.jpl.nasa.gov'\n",
    "\n",
    "    featured_image_url = beg_url + target_url_list[1]\n",
    "\n",
    "    return featured_image_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/chromedriver\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA19046_ip.jpg'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_feature_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "response = requests.get(twitter_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "twitter_results = soup.body.find_all('div', class_=\"js-tweet-text-container\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_tweets = []\n",
    "\n",
    "for tweet in twitter_results:\n",
    "    recent = tweet.find_all('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\")\n",
    "    \n",
    "    for tweet_text in recent:\n",
    "        recent_tweets.append(tweet_text.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Puerto Rico has NEXRAD Doppler radar again, just in time for hurricane season. Well done @NWSSanJuanhttps://twitter.com/adamonzon/status/1008092827815903232\\xa0…'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_recent_weather_tweet = recent_tweets[0]\n",
    "most_recent_weather_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_recent_weather_tweet():\n",
    "    \"\"\"Returns most recent tweet about weather on Mars\"\"\"\n",
    "    twitter_url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "    \n",
    "    response = requests.get(twitter_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    twitter_results = soup.body.find_all('div', class_=\"js-tweet-text-container\")\n",
    "    \n",
    "    recent_tweets = []\n",
    "\n",
    "    for tweet in twitter_results:\n",
    "        recent = tweet.find_all('p', class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\")\n",
    "        for tweet_text in recent:\n",
    "            recent_tweets.append(tweet_text.text.strip())\n",
    "            \n",
    "    most_recent_weather_tweet = recent_tweets[0]\n",
    "    \n",
    "    return most_recent_weather_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Puerto Rico has NEXRAD Doppler radar again, just in time for hurricane season. Well done @NWSSanJuanhttps://twitter.com/adamonzon/status/1008092827815903232\\xa0…'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_most_recent_weather_tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_url = \"https://space-facts.com/mars/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_pd = pd.read_html(mars_url)\n",
    "initial_mars_df = mars_pd[0]\n",
    "renamed_mars_df = initial_mars_df.rename(columns={0 : 'Scientific Measures', 1 : 'Values'})\n",
    "mars_df = renamed_mars_df.set_index('Scientific Measures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>Values</th>\\n    </tr>\\n    <tr>\\n      <th>Scientific Measures</th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Equatorial Diameter:</th>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <th>Polar Diameter:</th>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Distance:</th>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Period:</th>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <th>Surface Temperature:</th>\\n      <td>-153 to 20 °C</td>\\n    </tr>\\n    <tr>\\n      <th>First Record:</th>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <th>Recorded By:</th>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_html_table = mars_df.to_html()\n",
    "mars_html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>Values</th>    </tr>    <tr>      <th>Scientific Measures</th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>Equatorial Diameter:</th>      <td>6,792 km</td>    </tr>    <tr>      <th>Polar Diameter:</th>      <td>6,752 km</td>    </tr>    <tr>      <th>Mass:</th>      <td>6.42 x 10^23 kg (10.7% Earth)</td>    </tr>    <tr>      <th>Moons:</th>      <td>2 (Phobos &amp; Deimos)</td>    </tr>    <tr>      <th>Orbit Distance:</th>      <td>227,943,824 km (1.52 AU)</td>    </tr>    <tr>      <th>Orbit Period:</th>      <td>687 days (1.9 years)</td>    </tr>    <tr>      <th>Surface Temperature:</th>      <td>-153 to 20 °C</td>    </tr>    <tr>      <th>First Record:</th>      <td>2nd millennium BC</td>    </tr>    <tr>      <th>Recorded By:</th>      <td>Egyptian astronomers</td>    </tr>  </tbody></table>'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_html_table.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_df.to_html('mars_table.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mars_hemisphere_images():\n",
    "    \"\"\"Returns image urls of Mars Hemispheres\"\"\"\n",
    "    !which chromedriver\n",
    "    executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    hemispheres_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    browser.visit(hemispheres_url)\n",
    "\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    description_class = soup.find_all('div', class_='description')\n",
    "\n",
    "    hemisphere_names = []\n",
    "\n",
    "    for hemispheres in description_class:\n",
    "        hemisphere_names.append(hemispheres.find('h3').text)\n",
    "\n",
    "    start_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "    hemisphere_images_windows = []\n",
    "\n",
    "    for hemispheres_image in hemisphere_images:\n",
    "        browser.click_link_by_partial_text(hemispheres_image)\n",
    "        hemispheres_url = browser.url\n",
    "        new_page = soup.body.find_all('div', class_='container')\n",
    "        for sample in new_page:\n",
    "            browser.click_link_by_text('Sample')\n",
    "        hemisphere_images_windows.append(browser.windows)\n",
    "        browser.visit(start_url)\n",
    "    full_hemisphere_images = []\n",
    "\n",
    "    for full_images in hemisphere_images_windows[3]:\n",
    "        full_hemisphere_images.append(full_images.url)\n",
    "\n",
    "    full_hemisphere_image_urls = [\n",
    "        {\"title\": hemisphere_names[3], \"img_url\": full_hemisphere_images[1]},\n",
    "        {\"title\": hemisphere_names[2], \"img_url\": full_hemisphere_images[2]},\n",
    "        {\"title\": hemisphere_names[1], \"img_url\": full_hemisphere_images[3]},\n",
    "        {\"title\": hemisphere_names[0], \"img_url\": full_hemisphere_images[4]},\n",
    "    ]\n",
    "    \n",
    "    return full_hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
